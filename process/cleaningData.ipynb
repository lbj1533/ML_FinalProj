{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a87e318a-7a80-48a8-842f-9cfe48120d7f",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e04682-4665-4165-9889-7abeebf7a0b2",
   "metadata": {},
   "source": [
    "Below describes our process for cleaning the data, removing unwanted features, adding features, and normalizing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4877f336-12b6-4e94-ba94-b2cb9ead2162",
   "metadata": {},
   "source": [
    "## Dropping Unimportant Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60130a42-c228-4012-b0d6-a1302776a5ef",
   "metadata": {},
   "source": [
    "This section describes which features from the original data we remove and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0256caf2-9f32-4727-b337-66ec27ca450f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing libraries\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49f71c0d-6c73-4ec4-8e61-d85767c67943",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loading in data\n",
    "\n",
    "data_folder = \"../data/raw/\"\n",
    "file = data_folder + \"all_songs_data_raw.csv\"\n",
    "\n",
    "# concat all csvs into one dataframe\n",
    "df_list = [pd.read_csv(file)]\n",
    "\n",
    "raw_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f25d5a-1652-4d3d-83ec-918403e44291",
   "metadata": {},
   "source": [
    "We will start by removing any features that will not be useful due to their form, like \"Media\" or \"Writers\". These are URLs or other embedded information, and are not useful or interesting to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96ed53ae-1c9a-485b-bed1-09107d84968a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copying soon-to-be-cleaned data\n",
    "cleaned_df = raw_df.copy()\n",
    "\n",
    "# dropping writers and media columns\n",
    "cleaned_df = cleaned_df.drop(columns=[\"Media\", \"Writers\"])\n",
    "\n",
    "# also drop album and song urls\n",
    "cleaned_df = cleaned_df.drop(columns=[\"Album URL\", \"Song URL\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790d1d41-85ec-4b86-9b4f-a1d7bc5093ae",
   "metadata": {},
   "source": [
    "We will then drop features that are simply redundant, like \"Date\" when all we care about is predicting the year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402b011d-13c0-48df-978d-3021d4254a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.drop(columns=[\"Release Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863e4518-d6c0-4ee9-acd7-a10e4ef53feb",
   "metadata": {},
   "source": [
    "## Cleaning Data Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59d8b58-2a75-4bf0-b132-83fce66dfb45",
   "metadata": {},
   "source": [
    "This section will describe our process for cleaning up values in the data.\n",
    "\n",
    "The first values we will clean are all the values in the \"Year\" column. They are currently floats, when they can easily be ints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c405482-e73d-4646-9247-31496c20615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df[\"Year\"] = cleaned_df[\"Year\"].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9fc4d4-a150-4ca2-9762-5d7e1d98fb86",
   "metadata": {},
   "source": [
    "Next we will clean the \"Featured Artists\" column, as right now it is comprised of metadata, when we want the names of the artists only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e98cb65d-1260-4704-a8bd-ddafeb285404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "combined_artists_list = []\n",
    "\n",
    "for i, row in cleaned_df.iterrows():\n",
    "    artist = row[\"Artist\"]\n",
    "    featured_artists = row[\"Featured Artists\"]\n",
    "\n",
    "    # ensure featured artists is a string of a list of dicts\n",
    "    if isinstance(featured_artists, str) and featured_artists != \"[]\":\n",
    "        # convert if needed\n",
    "        featured_artists = ast.literal_eval(featured_artists)\n",
    "\n",
    "    if isinstance(featured_artists, list) and featured_artists:\n",
    "\n",
    "        # get all names\n",
    "        featured_artists_names = [fa['name'] for fa in featured_artists if isinstance(fa, dict) and 'name' in fa]\n",
    "\n",
    "        # combine names if they dont match\n",
    "        combined_artists = [artist]\n",
    "        for fa_name in featured_artists_names:\n",
    "            if fa_name.lower() not in artist.lower():\n",
    "                combined_artists.append(fa_name)\n",
    "                \n",
    "        # deals with adding to csv\n",
    "        combined_artists_list.append(\", \".join(combined_artists))\n",
    "    else:\n",
    "        combined_artists_list.append(artist)\n",
    "        \n",
    "cleaned_df[\"Artists\"] = combined_artists_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c61e7c-e557-4753-a50f-48288c7caf0b",
   "metadata": {},
   "source": [
    "There is still one more thing to be done with this column, though. Many bands are named \"[Main Vocalist] and the [Band Name]\", especially in the earlier years of this dataset. This should be treated as one artist, if possible. This is different from many songs today that have 2 or more artists separated by \"and\" in the format \"[1st Artist] and [2nd Artist]\". There needs to be a way to distinguish these two, as this may affect the model.\n",
    "\n",
    "We did this manually, as we wanted to improve our model's accuracy and R2. The code to do this is below. Note: Very unfortunately, this feature ended up not being useful, so it was removed along with plenty of others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fd943f6-06d0-44a8-bcfb-fb76a9341e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# list of known bands with either \"and\" or \"&\" in their name (was added manually)\n",
    "known_band_names = [\"Florence and the Machine\", \"Earth, Wind & Fire\", \"Simon & Garfunkel\", \"Santo and Johnny\", \n",
    "                    \"David Seville and The Chipmunks\", \"Johnny and The Hurricanes\", \"Dion and The Belmonts\", \n",
    "                    \"Phil Phillips and The Twilights\", \"Skip and Flip\", \"Jan and Dean\", \"Paul Evans and The Curls\"\n",
    "                   \"Hank Ballard and The Midnighters\", \"Ferrante and Teicher\", \"Shep and The Limelites\"\n",
    "                   \"Ike and Tina Turner\",\"Caesar and The Romans\",\"Rosie and The Originals\",\"Joey Dee and The Starlighters\"\n",
    "                   \"Jay and The Americans\",\"Don and Juan\", \"Booker T and The MG's\", \"Dick and Deedee\",\"Peter, Paul and Mary\"\n",
    "                   \"Jimmy Gilmer and The Fireballs\",\"Paul and Paula\",\"Martha and The Vandellas\",\"Randy and The Rainbows\",\n",
    "                   \"Ruby and The Romantics\",\"Garnet Mimms and The Enchanters\",\"Sunny and The Sunglows\",\"J. Frank Wilson and The Cavaliers\"\n",
    "                   \"Billy J. Kramer and The Dakotas\",\"Ronny and The Daytona\",\"Gerry and The Pacemakers\",\"Chad and Jeremy\",\n",
    "                   \"Robert Maxwell, His Harp and Orch.\",\"Sam The Sham and The Pharaohs\", \"Jr. Walker and The All Stars\",\n",
    "                   \"Sonny and Cher\", \"Gary Lewis and The Playboys\",\"Wayne Fontana and The Mindbenders\",\n",
    "                   \"Freddie and The Dreamers\", \"Peter and Gordon\",\"Little Anthony and The Imperials\",\"Dino, Desi and Billy\"\n",
    "                   \"? and The Mysterians\",\"Mama's and The Papa's\",\"Tommy James and The Shondells\",\"Paul Revere and The Raiders\"\n",
    "                   \"James and Bobby Purify\",\"Ray Conniff and The Singers\",\"Bobby Vee and The Strangers\",\n",
    "                   \"Sam and Dave\",\"Jay and The Techniques\",\"Diana Ross and The Supremes\",\"Peaches and Herb\",\n",
    "                   \"Archie Bell and The Drells\",\"Gary Puckett and The Union Gap\",\"Sly and The Family Stone\",\n",
    "                   \"John Fred and His Playboy Band\",\"Gene and Debbe\",\"Friend and Lover\",\"Sam and Dave\",\"Eric Burdon and The Animals\",\n",
    "                   \"Tommy Boyce and Bobby Hart\",\"Big Brother and The Holding Company\",\"Blood, Sweat and Tears\",\n",
    "                    \"Dennis Yost and The Classics IV\",\"Sonny Charles and The Checkmates, Ltd.\",\"Kenny Rogers and The First Edition\",\n",
    "                   \"Eric Burdon and War\",\"Melanie and The Edwin Hawkins Singers\",\"Alive and Kicking\",\"Charles Wright and The Watts 103rd Street Rhythm Band\",\n",
    "                   \"Pacific Gas and Electric\",\"Crosby, Stills, Nash and Young\",\"Cornelius Brothers and Sister Rose\",\n",
    "                    \"Hamilton, Joe Frank and Reynolds\",\"Brewer and Shipley\",\"Mac and Katie Kissoon\",\"Gladys Knight and The Pips\",\n",
    "                   \"Brenda and The Tabulations\",\"Mouth and MacNeal\",\"Derek and The Dominos\",\"Dr. Hook and The Medicine Show\",\n",
    "                   \"Commander Cody and His Lost Planet Airmen\",\"Tony Orlando and Dawn\",'Bobby \"Boris\" Pickett and The Crypt Kickers',\n",
    "                   \"Seals and Crofts\",\"Kool and The Gang\",\"Bo Donaldson and The Heywoods\",\"Donny and Marie Osmond\",\n",
    "                    \"K.C. and The Sunshine Band\",\"Disco Tex and The Sex-O-lettes\",\"Walter Murphy and The Big Apple Band\",\n",
    "                   \"Daryl Hall and John Oates\",\"England Dan and John Ford Coley\",\"Captain and Tennille\",\"Wing and A Prayer Fife and Drum Corps\",\n",
    "                   \"Marilyn McCoo and Billy Davis Jr.\",\"Crosby, Stills and Nash\",\"Bob Seger and The Silver Bullet Band\",\n",
    "                   \"Suzi Quatro and Chris Norman\",\"McFadden and Whitehead\",\"England Dan and John Ford Coley\",\n",
    "                   \"Ray, Goodman and Brown\",\"Franke and The Knockouts\",\"Stanley Clarke and George Duke\",\"Joan Jett and The Blackhearts\",\n",
    "                   \"Huey Lewis and The News\",\"John Cafferty and The Beaver Brown Band\",\"Sergio Mendes and Brasil '66\",\n",
    "                   \"Katrina and The Waves\",\"Ashford and Simpson\",\"Mike and The Mechanics\",\"Bruce Hornsby and The Range\",\n",
    "                    \"Lisa Lisa and Cult Jam\",\"Billy Vera and The Beaters\",\"Edie Brickell and The New Bohemians\",\"Marky Mark and The Funky Bunch\",\n",
    "                   \"D.J. Jazzy Jeff and The Fresh Prince\",\"Heavy D and The Boyz\",\"Hootie and The Blowfish\",\"B-Rock and The Bizz\",\n",
    "                   \"K-Ci and JoJo\",\"Lee Ann Womack and Sons Of The Desert\",\"Dan + Shay\",\"\"]\n",
    "\n",
    "def preprocess_artists(df):\n",
    "    def clean_artist_feature(row):\n",
    "        artist = row['Artist']\n",
    "        features = row['Featured Artists']\n",
    "        artist = artist.replace(\"uring\", \"\")\n",
    "        artist = re.sub(r'\\(.*?\\)', '', artist).strip()\n",
    "\n",
    "        # check if the artist is a known band, if so, leave it as-is\n",
    "        artist = artist.replace('Gary \"U.S.\" Bonds', 'Gary U.S. Bonds')\n",
    "        artist = artist.replace('James Brown and The Famous Flames', 'James Brown')\n",
    "        artist = artist.replace('Martha and The Vandella', 'Martha and The Vandellas')\n",
    "        artist = artist.replace('Sergio Mendes', \"Sergio Mendes and Brasil '66\")\n",
    "        artist = artist.replace('Smokey Robinson and The Miracles', \"Smokey Robinson\")\n",
    "        artist = artist.replace('Paul McCartney and Wings', \"Wings\")\n",
    "        artist = artist.replace('Paul and Linda McCartney', \"Paul McCartney\")\n",
    "        artist = artist.replace('Tom Petty and The Heartbreakers', \"Tom Petty\")\n",
    "        artist = artist.replace('Prince and The Revolution', \"Prince\")\n",
    "        artist = artist.replace('Prince and The New Power Generation', \"Prince\")\n",
    "        artist = artist.replace('Gloria Estefan and Miami Sound Machine', \"Gloria Estefan\")\n",
    "        artist = artist.replace('Heavy D. and The Boyz', \"Heavy D and The Boyz\")\n",
    "        artist = artist.replace('Jazzy Jeff and Fresh Prince', \"D.J. Jazzy Jeff and The Fresh Prince\")\n",
    "        artist = artist.replace('Snoop Doggy Dogg', \"Snoop Dogg\")\n",
    "        artist = artist.replace('Notorious B.I.G.', \"The Notorious B.I.G.\")\n",
    "        artist = artist.replace('Puff Daddy', \"Diddy\")\n",
    "        artist = artist.replace('P. Diddy', \"Diddy\")\n",
    "        artist = artist.replace('Missy \"Misdemeanor\" Elliott', \"Missy Elliott\")\n",
    "        artist = artist.replace('Musiq', \"Musiq Soulchild\")\n",
    "        artist = artist.replace('Lil Jon and The East Side Boyz', \"Lil Jon\")\n",
    "        artist = artist.replace('Pharrell Williams', \"Pharrell\")\n",
    "        artist = artist.replace(\"Lil'\", \"Lil\")\n",
    "        artist = artist.replace(\"Jay-Z/Linkin Park\", \"Jay-Z and Linkin Park\")\n",
    "        artist = artist.replace(\"Jay-Z + Alicia Keys\", \"Jay-Z and Alicia Keys\")\n",
    "        artist = artist.replace(\"Jay Z\", \"Jay-Z\")\n",
    "        artist = artist.replace(\"Soulja Boy Tell 'em\", \"Soulja Boy Tell'em\")\n",
    "        artist = artist.replace(\"Selena Gomez and The Scene\", \"Selena Gomez\")\n",
    "        artist = artist.replace(\"Alicia Keyes\", \"Alicia Keys\")\n",
    "        artist = artist.replace(\"Kesha\", \"Ke$ha\")\n",
    "        artist = artist.replace(\"Silk Sonic\", \"Bruno Mars and Anderson .Paak\")\n",
    "        artist = artist.replace(\"SpotemGottem featuring Pooh Shiesty / SpotemGottem featuring DaBaby\", \"SpotemGottem featuring DaBaby and Pooh Shiesty\")\n",
    "        \n",
    "                # Check if the artist is a known band, if so, leave it as-is\n",
    "        if artist in known_band_names:\n",
    "            return artist, features\n",
    "\n",
    "        # Regular expression to identify connectors for featured artists\n",
    "        # Matches \"feat.\", \"featuring\", \"feat\", \"&\", \" and \", \" with \"\n",
    "        pattern = r'\\s*(?:feat\\.?|featuring|&| and | with )\\s*'\n",
    "        parts = re.split(pattern, artist)\n",
    "\n",
    "        # If there are more than one part, it implies there are featured artists\n",
    "        if len(parts) > 1:\n",
    "            main_artist = parts[0].strip()  # The first part is the main artist\n",
    "            # Join remaining parts (excluding partial words like 'uring')\n",
    "            remaining_features = ' '.join(parts[1:]).strip()\n",
    "            # Split on commas and additional separators\n",
    "            extracted_features = [\n",
    "                p.strip() for p in re.split(r'[,&]', remaining_features) if p.strip()\n",
    "            ]\n",
    "            # Merge with existing featured artists\n",
    "            if isinstance(features, str) and features.strip():\n",
    "                all_features = extracted_features + eval(features)\n",
    "            else:\n",
    "                all_features = extracted_features\n",
    "            return main_artist, all_features\n",
    "        else:\n",
    "            # No splitting, return the artist as is\n",
    "            return artist.strip(), features\n",
    "\n",
    "    # Apply the cleaning function to each row in the dataframe\n",
    "    df[['Artist', 'Featured Artists']] = df.apply(\n",
    "        lambda row: clean_artist_feature(row), axis=1, result_type=\"expand\"\n",
    "    )\n",
    "\n",
    "    # Normalize featured artists into string format for easier analysis later\n",
    "    df['Featured Artists'] = df['Featured Artists'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "    return df\n",
    "    \n",
    "#cleaned_df = preprocess_artists(cleaned_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac882091-f324-455b-9674-147cca6bb1e1",
   "metadata": {},
   "source": [
    "## Removing Non-Applicable Data Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9486e459-9860-4834-8f09-6c395c6394e0",
   "metadata": {},
   "source": [
    "Now we will remove any instrumental songs. The \"lyrics\" are unpredictable in their representation and we cannot do sentiment analysis on them, so they must be removed. Oddly enough, there is no definite way to do this, but from looking at the data, removing any row with an empty lyrics, adverb, nouns, corpus or verbs column will do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "876aa008-34af-4018-a011-d807ec06c53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_df = cleaned_df.dropna(subset=[\"Lyrics\", \"Verbs\", \"Nouns\", \"Adverbs\", \"Corpus\"], how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d3d80e-bfca-4dae-8faa-6f595f0748b7",
   "metadata": {},
   "source": [
    "As you can see, all of the songs with the smallest number of lyrics have actual words instead of symbols or placeholders that would signify an instrumental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87b16299-f4f9-438d-9c97-e85ddd85a567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Lyrics  Word Counts\n",
      "5952  I love it when you call me A-nita cause it's m...           19\n",
      "1504  Spoken: Grand piano Reed and pipe organ Glocke...           26\n",
      "1849  Guess mine is not the first heart broken My ey...           28\n",
      "23    Sorry, sorry, oh so sorry SPOKEN: Uh-oh! **I r...           33\n",
      "1686  Baby face, youve got the cutest little baby fa...           55\n",
      "340   (Roy Orbison)  Sweet dream baby Sweet dream ba...           62\n",
      "845   Here he comes now I've got to tell him somehow...           62\n",
      "1318  DAY BY DAY GODSPELL Day by day (solo voice) Da...           65\n",
      "1007  This brand new album is called Hawaii Five-O P...           66\n",
      "2492   The dark side's callin' now Nothin' is real S...           66\n"
     ]
    }
   ],
   "source": [
    "print(cleaned_df.nsmallest(10, 'Word Counts')[['Lyrics', 'Word Counts']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bad5d82-0c6c-402c-a5e1-afe3424ffe94",
   "metadata": {},
   "source": [
    "## Creating New Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2607c546-7fcb-4317-8717-129bacb5f884",
   "metadata": {},
   "source": [
    "The below code creates a new feature that is the ratio between the total amount of words and the unique words, thus creating a \"Repetition Ratio\". For example, if a song has 180 words and the amount of unique words is 90, the repetition ratio is 2, meaning each word is said twice on average.\n",
    "\n",
    "Note: This feature ended up not being helpful to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf9e1bee-0359-4c2c-8d5a-ee62bb0b44e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_df[\"Repetition_Ratio\"] = cleaned_df[\"Word Counts\"] / cleaned_df[\"Unique Word Counts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12675bd-1cc7-4d4d-9c3d-b84754208244",
   "metadata": {},
   "source": [
    "The next feature we can create is the sentiment score for the corpus of the lyrics. In theory this method could be applied to the verbs, adverbs, nouns, etc. of the song, but this is unlikely to provide useful results. However, the model could use the sentiment score of the lyrics of a song to help predict its year, if there is a pattern.\n",
    "\n",
    "The following code will use Natural Language Toolkit for sentiment analysis on these lyrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c4e5932-4769-4d11-a70a-e8f704ab3adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package opinion_lexicon to\n",
      "[nltk_data]     /home/devel/nltk_data...\n",
      "[nltk_data]   Package opinion_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import opinion_lexicon\n",
    "from nltk import download\n",
    "\n",
    "# download lexicons\n",
    "download('opinion_lexicon')\n",
    "\n",
    "# set of pos and neg words\n",
    "positive_words = set(opinion_lexicon.positive())\n",
    "negative_words = set(opinion_lexicon.negative())\n",
    "\n",
    "# funct to apply to each song\n",
    "def lexicon_sentiment_score(tokens):\n",
    "\n",
    "    if not isinstance(tokens, list): \n",
    "        return 0.5\n",
    "    \n",
    "    # get pos and neg count\n",
    "    pos_count = sum(token in positive_words for token in tokens)\n",
    "    neg_count = sum(token in negative_words for token in tokens)\n",
    "    total = pos_count + neg_count\n",
    "\n",
    "    # return ratio aka sentiment score\n",
    "    return 0.5 if total == 0 else pos_count / total\n",
    "\n",
    "cleaned_df[\"Tokens\"] = cleaned_df[\"Corpus\"].str.lower().str.split() #pretokenize text\n",
    "cleaned_df[\"Lyrics_Sentiment\"] = cleaned_df[\"Tokens\"].apply(lexicon_sentiment_score)  # apply sentiment analysis\n",
    "cleaned_df = cleaned_df.drop(columns=\"Tokens\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa5973-262a-429c-af54-5bcd2877e795",
   "metadata": {},
   "source": [
    "Upon further analysis, it has been determined that more features would be helpful. We will apply the same sentiment analysis on the album names and the song names.\n",
    "\n",
    "Note: These features ended up not being helpful to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b6c973e-c51d-4cdf-8b34-71be45dcc458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cleaned_df[\"Tokens\"] = cleaned_df[\"Album\"].str.lower().str.split()\n",
    "#cleaned_df[\"Album_Sentiment\"] = cleaned_df[\"Tokens\"].apply(lexicon_sentiment_score)\n",
    "#cleaned_df = cleaned_df.drop(columns=\"Tokens\", axis=1)\n",
    "\n",
    "#cleaned_df[\"Tokens\"] = cleaned_df[\"Song Title\"].str.lower().str.split()\n",
    "#cleaned_df[\"Song_Sentiment\"] = cleaned_df[\"Tokens\"].apply(lexicon_sentiment_score)\n",
    "#cleaned_df = cleaned_df.drop(columns=\"Tokens\", axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001a6c2c-867c-4453-8e4f-9a45552d62ac",
   "metadata": {},
   "source": [
    "The following code will calculate the average number of words per sentence in the lyrics. This and the following features will be created so the model will have more to work from.\n",
    "\n",
    "Note: This feature ended up not being helpful to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c698643-d67a-4da5-8bdf-5d55ea7030bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def average_sentence_length(text):\n",
    "    # split into sentences\n",
    "    sentences = re.split(r'[.!?]', text)\n",
    "    sentences = [s.strip() for s in sentences if s.strip()]\n",
    "    # count total words\n",
    "    total_words = sum(len(sentence.split()) for sentence in sentences)\n",
    "    # avg sentence length\n",
    "    return total_words / len(sentences) if sentences else 0\n",
    "\n",
    "#cleaned_df['Avg_Sentence_Length'] = cleaned_df['Lyrics'].apply(average_sentence_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b13de26-0e1a-4282-9b6b-504951b1e3d8",
   "metadata": {},
   "source": [
    "The average word length may also be a helpful feature. The following code creates this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0bcbeb6-7c4e-4bd9-94fd-3ede2d24bc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(lyrics):\n",
    "    words = lyrics.split()\n",
    "    total_length = sum(len(word) for word in words)\n",
    "    return total_length / len(words) if words else 0\n",
    "\n",
    "cleaned_df['Avg_Word_Length'] = cleaned_df['Lyrics'].apply(average_word_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976c5420-e9f1-4139-bb29-0c3a50d61e66",
   "metadata": {},
   "source": [
    "We will add the Flesch-Kincaid Readability formula, again to give the model more to work with.\n",
    "\n",
    "Note: This feature ended up not being helpful to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f85bd0ba-1fbb-404c-a6e5-024127001ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat\n",
    "\n",
    "def calculate_readability_score(text):\n",
    "    return textstat.flesch_reading_ease(text)\n",
    "    \n",
    "#cleaned_df['Readability_Score'] = cleaned_df['Lyrics'].apply(calculate_readability_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8409479-dc90-4e67-bd52-4c641b25b795",
   "metadata": {},
   "source": [
    "We will also add number of verbs, nouns and adverbs. Note: This section has been added after noting feature importance with a Random Forest Model. It is apparent that the only standout feature is Word Count. We hope that adding more similar features, like the number of verbs, nouns and adverbs would be helpful to the model. Another Note: This seemed to have a positive impact, however, we believe that more features of a similar nature could help the model.\n",
    "\n",
    "Final Note: These features were ultimately not helpful to the model. They have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "186df811-b53e-49d3-8613-e72325018de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#cleaned_df['Verb_Count'] = cleaned_df['Verbs'].apply(lambda x: len(x.split()))\n",
    "#cleaned_df['Noun_Count'] = cleaned_df['Nouns'].apply(lambda x: len(x.split()))\n",
    "#cleaned_df['Adverb_Count'] = cleaned_df['Adverbs'].apply(lambda x: len(x.split()))\n",
    "\n",
    "#cleaned_df['Verb to Noun'] = cleaned_df['Verb_Count'] / cleaned_df['Noun_Count']\n",
    "#cleaned_df['Noun to Adverb'] = cleaned_df['Noun_Count'] / cleaned_df['Adverb_Count']\n",
    "#cleaned_df['Adverb to Verb'] = cleaned_df['Adverb_Count'] / cleaned_df['Verb_Count']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ab491c-c248-4b5a-bf15-6220579262b6",
   "metadata": {},
   "source": [
    "Two other features that may be able to help accuracy. We decided to use a one hot encoder to encode whether there was \"featured\" or \"feat\" in the song name, and whether there was \"and the\" in the artist. This should help the model get a bit more time-sensitive data. Note: This was not useful in the end. It has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a1d5a9a-4b71-4dfc-bb91-3570deea4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_df[\"Has_Featured\"] = cleaned_df['Song Title'].str.contains(r'\\b(feat\\.?|ft\\.?|featuring)\\b', case=False, regex=True).astype(int)\n",
    "#cleaned_df[\"Has_And_The\"] = cleaned_df['Artist'].str.contains(r'\\band the\\b', case=False, regex=True).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20f517-0ebb-4e72-a006-7d9ad62411c7",
   "metadata": {},
   "source": [
    "## Standardizing Non-Numeric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b25d8a-2e3e-4b9d-935b-665024f96175",
   "metadata": {},
   "source": [
    "The following will contain code on standardizing non-numeric features, so the model, again, has more to work with. We will use label encoding because of the memory efficiency in avoiding the extremely high dimensionality of all of the unique artists. This has its drawbacks, but we want to give the model all of the data it needs to find a pattern.\n",
    "\n",
    "The features we will label encode are Album and Artists. We will also scale them to be between 0 and 1 with a Standard Deviation of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "168d0704-ab08-4bea-b649-4b6c302471cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "cleaned_df['Album_Encoded'] = label_encoder.fit_transform(cleaned_df['Album'])\n",
    "cleaned_df['Artists_Encoded'] = label_encoder.fit_transform(cleaned_df['Artists'])\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cleaned_df['Artists_Normalized'] = scaler.fit_transform(cleaned_df[['Artists_Encoded']])\n",
    "cleaned_df['Album_Normalized'] = scaler.fit_transform(cleaned_df[['Album_Encoded']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61df69dd-d634-4ab2-b06d-19a8decc36db",
   "metadata": {},
   "source": [
    "## Standardizing Numeric Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e73c20-9c78-424b-97a6-e7eeb14f7be7",
   "metadata": {},
   "source": [
    "Rank needs to be standardized between 0 and 1, where lower ranks are better. Note: This feature ended up not being helpful to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5fa05e1-33ce-4b7e-b8ac-508de878cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "#cleaned_df['Rank'] = scaler.fit_transform(cleaned_df[['Rank']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e75d80e-c0f7-42e2-84cf-72368ff03a1b",
   "metadata": {},
   "source": [
    "We will continue to standardize features, now focusing on numerical features. We will standardize these to have a mean of 0, and a standard deviation of 1 for best results. Thus, we will use StandardScaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc4409dd-2b60-4d37-9363-c374afc513e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original features\n",
    "'''\n",
    "numerical_features = ['Word Counts', 'Unique Word Counts', 'Repetition_Ratio', \n",
    "                      'Lyrics_Sentiment', 'Song_Sentiment', 'Album_Sentiment',\n",
    "                      'Avg_Sentence_Length', 'Avg_Word_Length', 'Readability_Score', \n",
    "                      'Verb_Count', 'Adverb_Count', 'Noun_Count',\n",
    "                      'Verb to Noun', 'Noun to Adverb', 'Adverb to Verb'\n",
    "                     ]\n",
    "'''\n",
    "# trimmed features to be important\n",
    "numerical_features = ['Word Counts', 'Lyrics_Sentiment', 'Avg_Word_Length', 'Artists_Normalized', 'Album_Normalized']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "cleaned_df[numerical_features] = scaler.fit_transform(cleaned_df[numerical_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04ae1ee-cabe-4a96-9b1a-24eda0c10070",
   "metadata": {},
   "source": [
    "## Final Dropping of Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca6970f-a696-4aa0-813d-4e786030d4e7",
   "metadata": {},
   "source": [
    "We will now drop the features we have used to extract numerical and standardized features from. They can no longer be used by us, and the model cannot use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92b90b40-d545-4558-827f-3d05c1554e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\"Album\", \"Lyrics\", \"Rank\", \"Song Title\", \n",
    "                   \"Verbs\", \"Nouns\", \"Adverbs\", \"Corpus\", \n",
    "                   \"Featured Artists\", \"Artists\", \"Artist\", \"Album_Encoded\", \"Artists_Encoded\"]\n",
    "cleaned_df = cleaned_df.drop(columns=columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9031fb0-6cb7-4752-9bc2-aa65fc4c943e",
   "metadata": {},
   "source": [
    "## Saving the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abe71f8-f89c-4d23-80fb-c9d48b8897d8",
   "metadata": {},
   "source": [
    "Finally we save the cleaned data to its new location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "356d3c45-0024-468a-a972-06b71f836648",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data_folder = \"../data/cleaned/\"\n",
    "cleaned_file = cleaned_data_folder + \"all_songs_data_cleaned.csv\"\n",
    "os.makedirs(cleaned_data_folder, exist_ok=True)\n",
    "cleaned_df.to_csv(cleaned_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
